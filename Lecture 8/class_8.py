# -*- coding: utf-8 -*-
"""Class_8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vl9ZCZfeFod8Wg0Zc9jxQn78J6zz-iRJ
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

#Sample Dataset
data = {
    'X1': [1,2,3,4,5],
    'X2': [2,4,6,8,10],
    'Y': [3,6,9,12,15]
}
df = pd.DataFrame(data)
print(df)

X = df[['X1', 'X2']]
Y = df['Y']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

#Tarin the model
model = LinearRegression()
model.fit(X_train, Y_train)

#Predict Model
Y_pred = model.predict(X_test)

print('Coefficient:', model.coef_)
print('Intercept:', model.intercept_)

"""#Project 1

#Optimizing a Linear Model Using Gradient Descent
##Convert these Lines into Code

#Task 1
#Import NumPy library.
# Define the gradient_descent function with inputs X, y, learning_rate, and iterations.
#Initialize slope m and intercept c to 0.
#Store the number of observations in n.

#Task2
#Loop through the number of iterations for optimization.
# Calculate predicted values using the current m and c.
# Compute the gradient of m (partial derivative with respect to m).
dm = (-2/n)*np.sum(X*(y-y_pred))
#Compute the gradient of c (partial derivative with respect to c).
dc = (-2/n)*np.sum(y-y_pred)
#Update m using the learning rate and gradient.
m = m - leanrning_rate * dm
#Update c using the learning rate and gradient.
c = c - leanrning_rate * dc
#Return the optimized values of m and c.
"""

import numpy as np

# Gradient Descent function
def gradient_descent(X, y, learning_rate=0.01, iterations=1000):
    m, c = 0, 0

    n = len(y)
    for _ in range(iterations):
        y_pred = m * X + c
        dm = (-2/n) * np.sum(X * (y - y_pred))
        dc = (-2/n) * np.sum(y - y_pred)
        m = m - learning_rate * dm
        c = c - learning_rate * dc
    return m, c

"""#Task-3
###1. Define X and y as NumPy arrays of input and actual values
###2. Call the gradient_descent function to compute optimized m and c
###3. Print the optimized values of m and c

    # Sample dataset
    X = np.array([1, 2, 3, 4, 5])  # Independent variable
    y = np.array([2, 4, 6, 8, 10])  # Dependent variable

    # Running gradient descent to find the optimal m and c
    m, c = gradient_descent(X, y)

    # Displaying the results
    print("Optimized Slope (m):", m)
    print("Optimized Intercept (c):", c)
"""

# Sample dataset
X = np.array([1, 2, 3, 4, 5])  # Independent variable
y = np.array([2, 4, 6, 8, 10])  # Dependent variable

# Running gradient descent to find the optimal m and c
m, c = gradient_descent(X, y)

# Displaying the results
print("Optimized Slope (m):", m)
print("Optimized Intercept (c):", c)

#SVM Example
import numpy as np
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.datasets import make_classification

#Split Train and Test
X,y = make_classification(n_samples=100, n_features=2, n_classes=2, random_state=42, n_informative=2,
                          n_redundant=0, n_repeated=0, n_clusters_per_class=1, class_sep=1.5)

#Train the SVM by linear and rbf kernel
linear_svm  = SVC(kernel='linear')
linear_svm.fit(X,y)

#Fit the model
rbf_svm  = SVC(kernel='rbf', gamma='scale')
rbf_svm.fit(X,y)

import numpy as np
import matplotlib.pyplot as plt

def plot_decision_boundary(model, X, y, title):
    xx, yy = np.meshgrid(np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100),
                         np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 100))

    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    plt.figure(figsize=(6, 4))
    plt.contourf(xx, yy, Z, alpha=0.3, levels=1, cmap='coolwarm')
    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap='coolwarm')
    plt.title(title)
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.show()

plot_decision_boundary(linear_svm, X, y, "Linear SVM Decision Boundary")
plot_decision_boundary(rbf_svm, X, y, "RBF Kernel SVM Decision Boundary")

"""#Project 2

#Classifying Handwritten Digits with SVM
##Convert these Lines into Code

#Task 1
###1.Import the NumPy library.
###2.Import the Matplotlib library for plotting.
###3.Import the random module for selecting random test images.
###4.Import necessary functions from Scikit-learn, including:
1. datasets for loading the handwritten digits dataset.
2. train_test_split for splitting data into training and testing sets.
3. StandardScaler for normalizing the data.
4. SVC for training a Support Vector Machine (SVM) model.
5. classification_report for evaluating model performance.
"""

import numpy as np
import matplotlib.pyplot as plt
import random
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report

"""#Task 2
###1. Load the handwritten digits dataset using datasets.load_digits().
###2. Split the dataset into 80% training and 20% testing using train_test_split().
"""

# Load the handwritten digits dataset
digits = datasets.load_digits()
# Split dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)

"""#Task 3
###1. Standardize the feature values for better model performance
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

###2. Initialize and train an SVM model using an RBF kernel with gamma=0.01 and C=10.
    svm_digits = SVC(kernel='rbf', gamma=0.01, C=10)
    svm_digits.fit(X_train, y_train)

###3. Use the trained model to predict labels for the test dataset.
    y_pred = svm_digits.predict(X_test)

###4. Print a classification report displaying precision, recall, and F1-score for each digit class.
    print(classification_report(y_test, y_pred))

#Task 4
###1. Create a plot with 10 subplots (2 rows, 5 columns) to visualize random test images.
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))

###2. For each subplot:
1. Select a random test image.
2. Display the image in grayscale.
3. Set the title as the predicted label.
4. Remove axis labels for better visualization.


    for ax in axes.flat:
    index = random.randint(0, len(y_test) - 1)  # Ensure valid index
    ax.imshow(digits.images[index], cmap='gray')  # Use original image data
    ax.set_title(f"Pred: {y_pred[index]}")
    ax.axis("off")

###4. Adjust the layout for better spacing using plt.tight_layout().
1. plt.tight_layout()

###5. Display the plotted images using plt.show().
1. plt.show()

#
"""